% tex/discussao/dis_01_interpretacao.tex
\section{Interpretação Crítica dos Achados}
\label{sec:discussao_interpretacao}

\textbf{Análise Global do Comportamento do Modelo:} \\
Os resultados experimentais indicam, de forma inequívoca, que o modelo GraphRec implementado no MatchPredict-AI demonstra uma forte sensibilidade ao contexto do usuário. A comparação de desempenho entre o cenário \textit{Baseline} e os cenários de \textit{Persona} valida a hipótese central do trabalho: a introdução de um histórico de interações, mesmo que simulado, altera fundamentalmente o comportamento preditivo do modelo, provando a eficácia do `UserModel` em capturar e aplicar o contexto do usuário.

\textbf{A Dicotomia das Métricas: Poder de Ranqueamento vs. Calibração da Probabilidade:} \\
Uma das observações mais relevantes é a notável robustez da métrica AUC em contraste com a alta variabilidade de outras métricas como Acurácia, Precisão e Recall. A AUC, que avalia a capacidade do modelo de ranquear corretamente instâncias positivas acima de instâncias negativas, manteve-se em um nível excelente nos cenários \textit{Baseline} (0.970) e \textit{Persona Consistente} (0.965). Isso indica que o poder de discriminação fundamental do modelo, baseado na rica combinação de features multimodais e sociais, é sólido e resiliente.

No entanto, as métricas de classificação (Acurácia, Precisão, Recall), que dependem de um limiar de decisão fixo (0.5), revelaram uma dinâmica diferente. O histórico do usuário, especialmente um consistente, induz um forte viés positivo, empurrando as probabilidades de saída do modelo para os extremos. Como visto na Tabela \ref{tab:probabilidades_tcc2}, a probabilidade média para dislikes reais saltou de 0.052 para 0.817 no cenário consistente. Esse deslocamento da calibração de probabilidade resulta em um recall perfeito (pois quase nada é classificado como negativo), mas em uma precisão drasticamente reduzida. Isso sugere que o histórico atua como um poderoso modulador da "confiança" do modelo.

\textbf{O Impacto do Ruído na Discriminação do Modelo:} \\
O cenário \textit{Persona Inconsistente} revelou uma vulnerabilidade crítica e um insight profundo. A queda substancial na AUC para 0.821 neste cenário indica que o ruído e as contradições presentes no histórico do usuário não apenas prejudicam a calibração das probabilidades, mas também comprometem a capacidade fundamental do modelo de discriminar entre perfis preferíveis e não preferíveis. Em outras palavras, o modelo começa a cometer mais erros no próprio ranqueamento relativo, sugerindo que os sinais contextuais caóticos estão efetivamente "confundindo" sua compreensão das preferências subjacentes do usuário, em vez de apenas tornar suas predições menos assertivas.

\textbf{O Viés Contextual como uma Faca de Dois Gumes:} \\
Os resultados levantam uma discussão sobre o "viés" contextual aprendido pelo `UserModel`. Este componente aprende a adaptar suas predições com base no histórico, o que é desejável quando o histórico é representativo das preferências do usuário, como demonstrado pelo forte desempenho no cenário \textit{Persona Consistente}. Contudo, em uma aplicação real, este mesmo mecanismo precisa ser compreendido e potencialmente calibrado. Se um usuário, por exemplo, interage inicialmente apenas com um nicho muito específico de perfis, o modelo pode superespecializar-se rapidamente, criando uma "bolha de filtro" (\textit{filter bubble}) que o impede de descobrir outros perfis potencialmente interessantes. Em cenários onde o histórico é esparso ou ruidoso, o viés aprendido pode levar a recomendações subótimas. Portanto, em uma aplicação prática, seria necessário considerar mecanismos para mitigar vieses indesejados e promover a diversidade nas recomendações.