\section{Redes Neurais de Grafos (GNNs)}

\subsection{Introdução ao Conceito}

\textbf{Definição:}  
Redes Neurais de Grafos (GNNs) são uma classe de modelos de aprendizado profundo projetados para lidar com dados estruturados em grafos. Elas são capazes de capturar a topologia do grafo e aprender representações complexas de nós e arestas, aproveitando as relações intrínsecas e interações entre os componentes do grafo.

\textbf{Contextualização:}  
As GNNs têm sido amplamente adotadas em áreas como redes sociais, biologia computacional, sistemas de recomendação e processamento de linguagem natural, devido à sua capacidade de modelar dados não estruturados em um formato mais expressivo e relacional.

\subsection{Desenvolvimento Teórico}

\textbf{Explicação Detalhada:}

As GNNs operam por meio da agregação de informações dos nós vizinhos, utilizando diferentes mecanismos de atualização e propagação de mensagens. Os principais componentes e operações incluem:

\begin{itemize}
    \item \textbf{Propagação de Mensagens:} 
    Este é o processo pelo qual cada nó coleta informações de seus vizinhos para atualizar sua própria representação. A propagação de mensagens permite que as GNNs capturem a estrutura local e as dependências de longo alcance no grafo.

    \begin{equation}
    \mathbf{h}_i^{(l+1)} = \text{AGGREGATE} \left(\left\{\mathbf{h}_j^{(l)}, \forall j \in \mathcal{N}(i)\right\}\right)
    \end{equation}

    \begin{equation}
    \mathbf{h}_i^{(l+1)} = \text{UPDATE} \left(\mathbf{h}_i^{(l)}, \mathbf{h}_i^{(l+1)}\right)
    \end{equation}

    Onde \(\mathcal{N}(i)\) representa o conjunto de vizinhos do nó \(i\), e as funções AGGREGATE e UPDATE são projetadas para combinar e atualizar as informações dos nós.

    \item \textbf{Normalização e Agregação:} 
    Métodos de normalização, como normalização simétrica, são usados para garantir que a contribuição de cada vizinho seja balanceada de acordo com o grau do nó. Isso promove uma propagação de informações mais consistente e robusta através do grafo.

    \item \textbf{Funções de Ativação e Pesos Treináveis:} 
    Funções de ativação, como ReLU, são aplicadas às representações agregadas, e pesos treináveis são usados para aprender as melhores transformações durante o processo de treinamento.
\end{itemize}

\subsection{Componentes Técnicos}

\textbf{Fórmulas:}

1. \textbf{Propagação de Mensagens:}

\begin{equation}
\mathbf{h}_i^{(l+1)} = \sigma \left( \sum_{j \in \mathcal{N}(i)} \mathbf{W} \cdot \mathbf{h}_j^{(l)} + \mathbf{b} \right)
\end{equation}

Esta fórmula define a operação de uma camada em uma GNN, onde \(\mathbf{W}\) e \(\mathbf{b}\) são pesos treináveis, e \(\sigma\) é a função de ativação.

2. \textbf{Agregação com Normalização:}

\begin{equation}
\mathbf{h}_i^{(l+1)} = \sigma \left( \sum_{j \in \mathcal{N}(i)} \frac{1}{\sqrt{d_i d_j}} \mathbf{W} \cdot \mathbf{h}_j^{(l)} \right)
\end{equation}

Onde \(d_i\) e \(d_j\) são os graus dos nós \(i\) e \(j\), respectivamente.

\textbf{Diagramas/Imagens:}
\begin{itemize}
    \item (FIGURA 1: Exemplo de Grafo com Nós e Arestas)
    \item (FIGURA 2: Diagrama de Propagação de Mensagens em uma GNN)
    \item (FIGURA 3: Estrutura de Camadas de uma GNN)
\end{itemize}

\subsection{Conclusão}

As Redes Neurais de Grafos (GNNs) representam um avanço no aprendizado profundo, oferecendo um modo eficaz de modelar dados relacionais complexos. Em sistemas de recomendação para aplicativos de namoro, as GNNs podem ser utilizadas para explorar as interações e conexões sociais entre usuários. Ao modelar usuários e suas interações como nós e arestas, as GNNs conseguem identificar padrões de comportamento e compatibilidades baseadas não apenas em interesses comuns, mas também em influências sociais e interações passadas.

Essa abordagem pode aumentar a precisão das recomendações, ajudando a sugerir matches com maior potencial de sucesso e longevidade, oferecendo uma experiência de usuário mais personalizada e eficaz.
